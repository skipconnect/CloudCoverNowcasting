# This folder contains the different scripts we used for our datapreprocessing.

## More specifically we have

* 1) **2020.sh**
	Which is a bash-scripts generated at https://www.icare.univ-lille.fr/asd-content/extract/subset/ordergeo, used to download Cloud Mask (CMA)-images for 2020

* 2) **GenerateDownloadScripts.ipynb**
	Which is a a jupyter notebook used to take a bash-script as 2020.sh and convert it to a bash-script that calls the generate.py python script
	each time a complete download of a whole day has happend.
	Outputs a bash-script like 2020Complete.sh

* 3) **2020Complete.sh**
	Which as the new bash-script after GenerateDownloadScript

* 4) **generate.py** 
	Which is a python script that takes a downloaded day of CMA-images, converts it to a pytorch-file with altitude and land/sea mask concatenated.
	The script outputs a single day, with all times in a .pt file.

* 5) **Altitude.np** 
	Which is a numpy-file containing altitude information of input area

* 6) **LandSea.np**
	Which is a numpy-file containing Land/Sea information of input area.

* 7) **NewDataInspectionTest.ipynb**
	Which is a jupyter notebook file that inspects the CMA-images. Also it inspects the raw geotiff altitude and land/sea mask information.
	This NoteBook also projects raw-data to right CRS and downsamples and cropped to fit spatial resolution of input area as cloud data, and hence generate the files Altitude.np and LandSea.np.
	

* 8) **eea_r_3035_100_m_clc12_V18_5_land_mask.tif**
	which is the raw land/sea mask data in geotiff. File used in NewDataInspectionTest.ipynb to generate LandSea.np

* 9) **30N000E_20101117_gmted_mea300.tif and 50N000E_20101117_gmted_mea300.tif**
	Which is the raw altitude information in geotiff. These two files together cover the input area (as well as a bit more).
	Files used in NewDataInspectionTest.ipynb to generate Altitude.np

* 10) **dataloaders.ipynb**
	Which is a script that takes all the .pt files for every day generated by "generate.py" and makes chunks of data that all follows strictly after 
	eachother. So that all frames in a chunk are one long non disrupted sequence. If we get missing data on a day, we will break the sequence and 
	make a new chunk. There are two versions, one with only cloud information and one with all features. 
